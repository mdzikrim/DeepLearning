{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO1rcXI3CWaNYaulsJHxfN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdzikrim/DeepLearning/blob/main/IMDB_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "qirvZHySdsU1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDB dataset dari Keras\n",
        "num_words = 40000\n",
        "maxlen = 400\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Konversi ke tensor PyTorch\n",
        "x_train = torch.tensor(x_train, dtype=torch.long)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "x_test = torch.tensor(x_test, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Dataset & DataLoader\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "train_dataset = IMDBDataset(x_train, y_train)\n",
        "test_dataset = IMDBDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128)\n"
      ],
      "metadata": {
        "id": "VG4pzZlffkdI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm1 = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim // 2, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim // 2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = x[:, -1, :]  # Ambil output dari timestep terakhir\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMModel(vocab_size=num_words, embed_dim=128, hidden_dim=128).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "UQeA0gOpfuPa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device).unsqueeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "RS8JNucWfyAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6e5811-b5c9-47ed-9db2-6969666fca94"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 116.2108\n",
            "Epoch 2/5, Loss: 111.4064\n",
            "Epoch 3/5, Loss: 93.8419\n",
            "Epoch 4/5, Loss: 86.8551\n",
            "Epoch 5/5, Loss: 78.1458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x = batch_x.to(device)\n",
        "        outputs = model(batch_x).cpu().numpy().ravel()\n",
        "        all_preds.extend(outputs)\n",
        "        all_labels.extend(batch_y.numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_classes = (all_preds > 0.5).astype(int)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Hitung metrik\n",
        "accuracy = accuracy_score(all_labels, all_classes)\n",
        "precision = precision_score(all_labels, all_classes)\n",
        "recall = recall_score(all_labels, all_classes)\n",
        "f1 = f1_score(all_labels, all_classes)\n",
        "auc = roc_auc_score(all_labels, all_preds)\n",
        "\n",
        "# Cetak hasil\n",
        "print(\"📊 Evaluasi Model:\")\n",
        "print(f\"Accuracy  : {accuracy:.4f}\")\n",
        "print(f\"Precision : {precision:.4f}\")\n",
        "print(f\"Recall    : {recall:.4f}\")\n",
        "print(f\"F1 Score  : {f1:.4f}\")\n",
        "print(f\"AUC ROC   : {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zVoIEtDDto8",
        "outputId": "01bb8017-78c2-4698-b0ed-e7fb10cf0e79"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Evaluasi Model:\n",
            "Accuracy  : 0.7695\n",
            "Precision : 0.9039\n",
            "Recall    : 0.6030\n",
            "F1 Score  : 0.7235\n",
            "AUC ROC   : 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
      ],
      "metadata": {
        "id": "la3vx6WA5548"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "num_words = 30000\n",
        "maxlen = 500\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "8uAGKU_A6Ud8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=128, input_length=maxlen),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFaQ90HX6F8l",
        "outputId": "81b87f38-8cda-409a-c56a-eae1414d2812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test, y_test)\n",
        ")\n",
        "\n",
        "# Print summary of last epoch\n",
        "print(\"\\nLast epoch metrics:\")\n",
        "print(f\"Loss: {history.history['loss'][-1]:.4f}\")\n",
        "print(f\"Accuracy: {history.history['accuracy'][-1]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkYRSwTF6J3m",
        "outputId": "1d2768eb-9d3c-437c-9893-f5040acf51c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1664s\u001b[0m 8s/step - accuracy: 0.6001 - loss: 0.6379 - val_accuracy: 0.8478 - val_loss: 0.3607\n",
            "Epoch 2/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1801s\u001b[0m 9s/step - accuracy: 0.9014 - loss: 0.2641 - val_accuracy: 0.8594 - val_loss: 0.3646\n",
            "Epoch 3/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1658s\u001b[0m 8s/step - accuracy: 0.9491 - loss: 0.1454 - val_accuracy: 0.8554 - val_loss: 0.4344\n",
            "Epoch 4/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1686s\u001b[0m 8s/step - accuracy: 0.9617 - loss: 0.1091 - val_accuracy: 0.8685 - val_loss: 0.4225\n",
            "Epoch 5/5\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1624s\u001b[0m 8s/step - accuracy: 0.9766 - loss: 0.0752 - val_accuracy: 0.8646 - val_loss: 0.5260\n",
            "\n",
            "Last epoch metrics:\n",
            "Loss: 0.0765\n",
            "Accuracy: 0.9762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities and binary output\n",
        "y_pred_prob = model.predict(x_test).flatten()\n",
        "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, y_pred_prob)\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"Accuracy  : {acc:.4f}\")\n",
        "print(f\"Precision : {prec:.4f}\")\n",
        "print(f\"Recall    : {rec:.4f}\")\n",
        "print(f\"F1 Score  : {f1:.4f}\")\n",
        "print(f\"AUC Score : {auc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKzu6WRI6MSB",
        "outputId": "8ebd35ea-dc5b-446c-a6a9-a54418dbada2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m633s\u001b[0m 809ms/step\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy  : 0.8646\n",
            "Precision : 0.8635\n",
            "Recall    : 0.8662\n",
            "F1 Score  : 0.8648\n",
            "AUC Score : 0.9337\n"
          ]
        }
      ]
    }
  ]
}
